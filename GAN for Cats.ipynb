{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e99c070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08402ff1",
   "metadata": {},
   "source": [
    "# Prepare the Dataset\n",
    "### 15747 images (64,64,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8b84ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15747, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"./cats\"\n",
    "\n",
    "dataset = []\n",
    "for each in os.listdir(dataset_dir):\n",
    "    image = cv2.imread(os.path.join(dataset_dir, each))\n",
    "    if type(image) != type(None):\n",
    "        dataset.append(image)\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "41f948df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.min(), dataset.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7585d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = (dataset - 127.5)/127.5    # Normalize the images to [-1, 1]\n",
    "dataset.min(), dataset.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f58312d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float64, name=None)>\n"
     ]
    }
   ],
   "source": [
    "# Batch and shuffle the data\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 15747\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(dataset).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72862707",
   "metadata": {},
   "source": [
    "# Create the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794489c",
   "metadata": {},
   "source": [
    "## Generator \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c5ae3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model(noise_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(4*4*1024, input_shape=(noise_dim,)))\n",
    "    model.add(layers.Reshape((4, 4, 1024)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(filters=512, kernel_size=(5,5), strides=(2,2), padding='same',\n",
    "            kernel_initializer=tf.initializers.truncated_normal(stddev=0.02)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(filters=256, kernel_size=(5,5), strides=(2,2), padding='same',\n",
    "             kernel_initializer=tf.initializers.truncated_normal(stddev=0.02)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(filters=128, kernel_size=(5,5), strides=(2,2), padding='same',\n",
    "             kernel_initializer=tf.initializers.truncated_normal(stddev=0.02)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "\n",
    "    model.add(layers.Conv2DTranspose(filters=64, kernel_size=(5,5), strides=(2,2), padding='same',\n",
    "             kernel_initializer=tf.initializers.truncated_normal(stddev=0.02)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(filters=3, kernel_size=(5,5), strides=(1,1), padding='same',\n",
    "             kernel_initializer=tf.initializers.truncated_normal(stddev=0.02),\n",
    "             activation='tanh'))\n",
    "    # output (64,64,3)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e618ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[-1.65877427e-04 -1.73718130e-04  1.87302299e-04]\n",
      "   [-1.03455421e-03  1.12121610e-03  6.95876428e-04]\n",
      "   [-1.41342593e-04  3.70484369e-04 -1.11234636e-04]\n",
      "   ...\n",
      "   [ 3.19103105e-03  1.20744179e-03  1.70672208e-03]\n",
      "   [ 1.25637569e-03 -3.58620688e-04  1.25150010e-03]\n",
      "   [-3.52327945e-04  1.73178909e-03 -1.83317883e-04]]\n",
      "\n",
      "  [[ 7.81163806e-04  5.99441933e-04  3.97345459e-04]\n",
      "   [-3.84166669e-05 -8.07410106e-05  2.25910146e-04]\n",
      "   [ 3.54581454e-04  3.79597041e-04  4.16760711e-04]\n",
      "   ...\n",
      "   [ 1.12448691e-03  3.12546501e-03  1.45455904e-03]\n",
      "   [-1.53538527e-03  1.33354205e-03 -1.68726943e-03]\n",
      "   [ 2.85186456e-04 -3.41889885e-04  1.19114923e-03]]\n",
      "\n",
      "  [[-3.37177946e-04  4.79170412e-04  5.01619361e-04]\n",
      "   [ 1.97532238e-03  1.26999058e-03 -4.70501924e-04]\n",
      "   [-4.89802565e-04 -1.81350231e-04  4.04699131e-05]\n",
      "   ...\n",
      "   [-5.84108871e-04  3.60347959e-03  2.65766052e-04]\n",
      "   [ 2.57850671e-03  2.26751249e-03  5.71936951e-04]\n",
      "   [-2.49507662e-04  6.02597254e-04  2.87286130e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-2.07499182e-03  1.19293306e-03 -4.80733870e-04]\n",
      "   [-1.94234692e-03  2.80532823e-03  8.04075331e-04]\n",
      "   [ 1.29692210e-03  5.04715659e-04  3.74177092e-04]\n",
      "   ...\n",
      "   [-2.22024438e-03  4.52364190e-03 -3.41138733e-03]\n",
      "   [ 8.04433413e-03  6.97493926e-03  2.01901630e-03]\n",
      "   [ 4.22272505e-03  2.37578619e-03 -1.79639715e-03]]\n",
      "\n",
      "  [[ 7.85805751e-04  2.08579632e-03  7.17006274e-04]\n",
      "   [ 4.51956497e-04  1.49835809e-03  8.19606823e-04]\n",
      "   [ 3.18278690e-05  2.72376486e-03  1.02932483e-03]\n",
      "   ...\n",
      "   [-8.51252524e-04  5.58682671e-03 -2.20162538e-03]\n",
      "   [-2.72061490e-03 -4.45862621e-04  4.80572367e-03]\n",
      "   [ 7.08256848e-04  4.69809445e-03  6.21290237e-04]]\n",
      "\n",
      "  [[ 1.16504449e-03  2.04204884e-03  1.93964003e-03]\n",
      "   [-1.80471234e-03 -1.91632607e-05 -3.47377296e-04]\n",
      "   [ 5.33177168e-04  2.22473009e-03  1.84285140e-03]\n",
      "   ...\n",
      "   [ 8.19785346e-04  2.96639977e-03 -1.68027205e-03]\n",
      "   [ 2.19393196e-03  6.60927594e-03  1.64315884e-03]\n",
      "   [-1.89780060e-03  2.27605645e-03  2.03302596e-03]]]], shape=(1, 64, 64, 3), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c61d12b0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "noise_dim = 100\n",
    "generator = generator_model(noise_dim)\n",
    "noise = tf.random.normal([1, noise_dim])\n",
    "generated_image = generator(noise, training=False)\n",
    "print(generated_image)\n",
    "plt.imshow(generated_image[0, :, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4607b1",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88451a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=(64, 64, 3)))\n",
    "    model.add(layers.BatchNormalization(epsilon = 1e-5))\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(5,5), strides=(2,2), padding='same'))\n",
    "    model.add(layers.BatchNormalization(epsilon = 1e-5))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2D(filters=256, kernel_size=(5,5), strides=(2,2), padding='same'))\n",
    "    model.add(layers.BatchNormalization(epsilon = 1e-5))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2D(filters=512, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
    "    model.add(layers.BatchNormalization(epsilon = 1e-5))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2D(filters=1024, kernel_size=(5,5), strides=(2,2), padding='same'))\n",
    "    model.add(layers.BatchNormalization(epsilon = 1e-5))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid')) # relu or sigmoid ?!\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f5a0a186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.49993718]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a771cd4",
   "metadata": {},
   "source": [
    "## Model Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b762d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2207cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "df6bba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a1795a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = Adam(1e-4)\n",
    "discriminator_optimizer = Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3236d88",
   "metadata": {},
   "source": [
    "### Save Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "de4c95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bdd704",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4a35b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "27e535e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    print(noise)\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cf169f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "            \n",
    "        # Produce images for the GIF as you go\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "        \n",
    "        # Save the model every 15 epochs\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "          checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "        \n",
    "    # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2350ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :] * 0.5 + 0.5)\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "85178702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_normal:0\", shape=(256, 100), dtype=float32)\n",
      "Tensor(\"random_normal:0\", shape=(256, 100), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[106], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Produce images for the GIF as you go\u001b[39;00m\n\u001b[1;32m      9\u001b[0m display\u001b[38;5;241m.\u001b[39mclear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cafc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
